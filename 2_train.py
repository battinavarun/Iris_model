# ============================================================
# 2_train.py â€” Step 2: Train & Save the ML Model
# ============================================================
# This script:
#   1. Loads and preprocesses the data
#   2. Splits data into training & test sets
#   3. Trains a Random Forest classifier
#   4. Evaluates accuracy
#   5. Saves the model to model.pkl
#
# Command: python 2_train.py
# ============================================================

import pandas as pd
import pickle
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("=" * 50)
print("ğŸ¤–  MODEL TRAINING")
print("=" * 50)

# â”€â”€ 1. Load data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ“‚ Loading dataset...")
df = pd.read_csv("iris.csv")

# â”€â”€ 2. Split features (X) and label (y) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# X = all columns EXCEPT the species column (these are the inputs)
# y = just the species column (this is what we want to predict)
X = df.drop(columns=["species"])
y = df["species"]

print(f"   Features (X): {list(X.columns)}")
print(f"   Target   (y): species  [{', '.join(y.unique())}]")

# â”€â”€ 3. Split into training and testing sets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 80% of data is used for training, 20% for testing
# random_state=42 ensures the same split every time you run it
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nâœ‚ï¸  Train/Test split:")
print(f"   Training samples : {len(X_train)} ({len(X_train)/len(df)*100:.0f}%)")
print(f"   Testing  samples : {len(X_test)}  ({len(X_test)/len(df)*100:.0f}%)")

# â”€â”€ 4. Create and train the model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Random Forest = many decision trees working together (more accurate!)
print("\nğŸŒ² Training Random Forest model...")
model = RandomForestClassifier(
    n_estimators=100,   # number of trees in the forest
    random_state=42     # for reproducibility
)
model.fit(X_train, y_train)
print("   âœ… Training complete!")

# â”€â”€ 5. Evaluate on the test set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"\nğŸ“Š Model Accuracy: {accuracy * 100:.2f}%")
print("\nğŸ“‹ Detailed Report:")
print(classification_report(y_test, y_pred))

print("ğŸ”¢ Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred, labels=["setosa", "versicolor", "virginica"])
print(f"                setosa  versicolor  virginica")
for label, row in zip(["setosa", "versicolor", "virginica"], cm):
    print(f"   {label:<12}  {row[0]:<7} {row[1]:<11} {row[2]}")

# â”€â”€ 6. Feature importance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nâ­ Feature Importances (which features matter most):")
for feature, importance in sorted(
    zip(X.columns, model.feature_importances_), key=lambda x: -x[1]
):
    bar = "â–ˆ" * int(importance * 40)
    print(f"   {feature:<15} {importance:.4f}  {bar}")

# â”€â”€ 7. Save model to disk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open("model.pkl", "wb") as f:
    pickle.dump(model, f)

print("\nğŸ’¾ Model saved as 'model.pkl'")
print("\nâœ… Training complete! Move on to: python 3_predict.py")